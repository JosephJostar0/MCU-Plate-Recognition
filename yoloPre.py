from ultralytics.yolo.engine.predictor import BasePredictor
from ultralytics.yolo.engine.results import Results
from ultralytics.yolo.utils import DEFAULT_CFG, LOGGER, SETTINGS, callbacks, ops
from ultralytics.yolo.utils.plotting import Annotator, colors, save_one_box
from ultralytics.yolo.utils.torch_utils import smart_inference_mode
from ultralytics.yolo.utils.files import increment_path
from ultralytics.yolo.utils.checks import check_imshow
from ultralytics.yolo.cfg import get_cfg
import queue

from lprr import CHARS
from collections import defaultdict
from pathlib import Path
from lprr.plate import de_lpr, dr_plate
import numpy as np
import time
import torch
import cv2

waitQueue = queue.Queue()
runFlag = True


class YoloPredictor(BasePredictor):
    global waitQueue, runFlag

    def __init__(self, cfg=DEFAULT_CFG, overrides=None):

        # å¤šé‡ç»§æ‰¿
        super(YoloPredictor, self).__init__()

        self.carNumList = []

        # get_cfg() å‡½æ•°å¯ä»¥ä»é…ç½®æ–‡ä»¶ä¸­è·å–å‚æ•° ã€ä½¿ç”¨ self.args ä¿å­˜æœ€ç»ˆçš„é…ç½®ã€‘
        self.args = get_cfg(cfg, overrides)

        project = self.args.project or Path(
            SETTINGS['runs_dir']) / self.args.task
        name = f'{self.args.mode}'
        self.save_dir = increment_path(
            Path(project) / name, exist_ok=self.args.exist_ok)

        self.done_warmup = False
        if self.args.show:
            self.args.show = check_imshow(warn=True)

        # æˆ‘å®šä¹‰çš„å±æ€§
        self.iscamera = 0
        self.capture_frame = None

        # GUI args
        self.used_model_name = None  # The detection model name to use
        self.new_model_name = None  # Models that change in real time
        self.source = ''  # input source
        self.stop_dtc = False  # Termination detection
        self.continue_dtc = True  # pause
        self.save_res = False  # Save test results
        self.save_txt = False  # save label(txt) file
        self.iou_thres = 0.45  # iou
        self.conf_thres = 0.25  # conf
        self.speed_thres = 10  # delay, ms
        self.labels_dict = {}  # return a dictionary of results
        self.progress_value = 0  # progress bar

        # Usable if setup is done
        self.model = None
        self.data = self.args.data  # data_dict
        self.imgsz = None
        self.device = None
        self.dataset = None
        self.vid_path, self.vid_writer = None, None
        self.annotator = None
        self.data_path = None
        self.source_type = None
        self.batch = None
        self.callbacks = defaultdict(
            list, callbacks.default_callbacks)  # add callbacks
        callbacks.add_integration_callbacks(self)

    def beforeRun(self, modeName: str = r'.\models\car.pt'):
        self.new_model_name = modeName
        self.save_res = True
        self.save_txt = True

        if self.args.verbose:
            LOGGER.info('')

        # print('åŠ è½½æ¨¡å‹')
        if not self.model:
            self.setup_model(self.new_model_name)
            self.used_model_name = self.new_model_name
            if self.save_res or self.save_txt:
                (self.save_dir / 'labels' if self.save_txt else self.save_dir).mkdir(
                    parents=True, exist_ok=True)

    # main for detect
    @smart_inference_mode()
    def run(self):
        global runFlag
        try:
            while runFlag:
                self.source = waitQueue.get(timeout=3)

                # set source  [è§†é¢‘èµ„æº]
                # print('è®¾ç½®èµ„æºæ¨¡å¼')
                self.setup_source(
                    self.source if self.source is not None else self.args.source)

                if not self.done_warmup:
                    # è°ƒç”¨æ¨¡å‹çš„ warmup å‡½æ•°ï¼Œå…¶ä¸­ imgsz å‚æ•°ä¸ºè¾“å…¥å›¾åƒçš„å¤§å°
                    # å¦‚æœæ¨¡å‹ä½¿ç”¨ PyTorchï¼Œimgsz å‚æ•°åº”ä¸º [batch_size, channels, height, width]
                    # å¦‚æœæ¨¡å‹ä½¿ç”¨ Tritonï¼Œimgsz å‚æ•°åº”ä¸º [height, width, channels, batch_size]
                    self.model.warmup(imgsz=(
                        1 if self.model.pt or self.model.triton else self.dataset.bs, 3, *self.imgsz))
                    # å°† done_warmup æ ‡è®°ä¸º Trueï¼Œä»¥æ ‡è®°æ¨¡å‹å·²ç»çƒ­èº«è¿‡
                    self.done_warmup = True
                self.seen, self.windows, self.dt, self.batch = 0, [
                ], (ops.Profile(), ops.Profile(), ops.Profile()), None
                # åˆ›å»ºåä¸º dt çš„å®ä¾‹å˜é‡ï¼Œç”¨äºå­˜å‚¨ä¸€ä¸ªå…ƒç»„ï¼Œå¹¶å°†å…¶åˆå§‹åŒ–ä¸ºåŒ…å«ä¸‰ä¸ªå¯¹è±¡ ops.Profile() çš„å…ƒç»„ã€‚
                # ops.Profile() æ˜¯æŒ‡ä» ops æ¨¡å—ä¸­å¯¼å…¥åä¸º Profile() çš„å¯¹è±¡ã€‚

                count = 0  # run location frame
                start_time = time.time()  # used to calculate the frame rate
                batch = iter(self.dataset)
                while True:
                    # Termination detection  ã€ç»ˆæ­¢æ£€æµ‹ã€‘
                    if self.stop_dtc:
                        # é‡Šæ”¾CV2è§†é¢‘å†™å…¥å™¨
                        if isinstance(self.vid_writer[-1], cv2.VideoWriter):
                            # release final video writer
                            self.vid_writer[-1].release()
                        # self.yolo2main_status_msg.emit('Detection terminated!')
                        break

                    # Change the model midway ã€åˆ‡æ¢modelã€‘  å¦‚æœä¸ç›¸ç­‰ï¼Œåˆ™æ‰§è¡Œ setup_model() æ–¹æ³•è®¾ç½®æ–°çš„æ¨¡å‹
                    if self.used_model_name != self.new_model_name:
                        # self.yolo2main_status_msg.emit('Change Model...')
                        self.setup_model(self.new_model_name)
                        self.used_model_name = self.new_model_name

                    # pause switch  ç”¨äºæ§åˆ¶ç¨‹åºçš„æš‚åœå’Œç»§ç»­
                    if self.continue_dtc:
                        # time.sleep(0.001)
                        # self.yolo2main_status_msg.emit('Detecting...')
                        batch = next(self.dataset)  # next data

                        self.batch = batch
                        path, im, im0s, vid_cap, s = batch
                        visualize = increment_path(self.save_dir / Path(path).stem,
                                                   mkdir=True) if self.args.visualize else False

                        # Calculation completion and frame rate (to be optimized)
                        count += 1  # frame count +1
                        if vid_cap:
                            all_count = vid_cap.get(
                                cv2.CAP_PROP_FRAME_COUNT)  # total frames
                        else:
                            all_count = 1
                        self.progress_value = int(
                            count / all_count * 1000)  # progress bar(0~1000)
                        if count % 5 == 0 and count >= 5:  # Calculate the frame rate every 5 frames
                            # self.yolo2main_fps.emit(
                            # str(int(5 / (time.time() - start_time))))
                            start_time = time.time()

                        # preprocess
                        # self.dt åŒ…å«äº†ä¸‰ä¸ª DetectorTime ç±»å‹çš„å¯¹è±¡ï¼Œè¡¨ç¤ºé¢„å¤„ç†ã€æ¨ç†å’Œåå¤„ç†æ‰€èŠ±è´¹çš„æ—¶é—´

                        # ä½¿ç”¨ with è¯­å¥è®°å½•ä¸‹ä¸‹ä¸€è¡Œä»£ç æ‰€èŠ±è´¹çš„æ—¶é—´ï¼Œself.dt[0] è¡¨ç¤ºè®°å½•é¢„å¤„ç†æ“ä½œæ‰€èŠ±è´¹çš„æ—¶é—´ã€‚
                        with self.dt[0]:
                            # è°ƒç”¨ self.preprocess æ–¹æ³•å¯¹å›¾åƒè¿›è¡Œå¤„ç†ï¼Œå¹¶å°†å¤„ç†åçš„å›¾åƒèµ‹å€¼ç»™ im å˜é‡ã€‚
                            im = self.preprocess(im)
                            # å¦‚æœ im çš„ç»´åº¦ä¸º 3ï¼ˆRGB å›¾åƒï¼‰ï¼Œåˆ™è¡¨ç¤ºè¿™æ˜¯ä¸€å¼ å•å¼ å›¾åƒï¼Œéœ€è¦å°†å…¶æ‰©å±•æˆ 4 ç»´ï¼ŒåŠ ä¸Š batch ç»´åº¦ã€‚
                            if len(im.shape) == 3:
                                im = im[None]  # expand for batch dim  æ‰©å¤§æ‰¹é‡è°ƒæš—
                        # inference
                        with self.dt[1]:
                            # è°ƒç”¨æ¨¡å‹å¯¹å›¾åƒè¿›è¡Œæ¨ç†ï¼Œå¹¶å°†ç»“æœèµ‹å€¼ç»™ preds å˜é‡ã€‚
                            preds = self.model(
                                im, augment=self.args.augment, visualize=visualize)
                        # postprocess
                        with self.dt[2]:
                            # è°ƒç”¨ self.postprocess æ–¹æ³•å¯¹æ¨ç†ç»“æœè¿›è¡Œåå¤„ç†ï¼Œå¹¶å°†ç»“æœä¿å­˜åˆ° self.results å˜é‡ä¸­ã€‚
                            # å…¶ä¸­ preds æ˜¯æ¨¡å‹çš„é¢„æµ‹ç»“æœï¼Œim æ˜¯æ¨¡å‹è¾“å…¥çš„å›¾åƒï¼Œè€Œ im0s æ˜¯åŸå§‹å›¾åƒçš„å¤§å°ã€‚
                            self.results = self.postprocess(preds, im, im0s)

                        # visualize, save, write results
                        n = len(im)  # To be improved: support multiple img
                        for i in range(n):
                            self.results[i].speed = {
                                'preprocess': self.dt[0].dt * 1E3 / n,
                                'inference': self.dt[1].dt * 1E3 / n,
                                'postprocess': self.dt[2].dt * 1E3 / n}
                            p, im0 = (path[i], im0s[i].copy()) if self.source_type.webcam or self.source_type.from_img \
                                else (path, im0s.copy())

                            p = Path(p)  # the source dir

                            # s:::   video 1/1 (6/6557) 'path':
                            # must, to get boxs\labels
                            # labels   /// original :s +=
                            label_str = self.write_results(
                                i, self.results, (p, im, im0))

                            # labels and nums dict
                            class_nums = 0
                            target_nums = 0
                            self.labels_dict = {}
                            if 'no detections' in label_str:
                                pass
                            else:
                                for ii in label_str.split(',')[:-1]:
                                    nums, label_name = ii.split('~')
                                    self.labels_dict[label_name] = int(nums)
                                    target_nums += int(nums)
                                    class_nums += 1

                            # save img or video result
                            if self.save_res:
                                self.save_preds(vid_cap, i, str(
                                    self.save_dir / p.name))

                    # Detection completed
                    if count + 1 >= all_count:
                        if isinstance(self.vid_writer[-1], cv2.VideoWriter):
                            # release final video writer
                            self.vid_writer[-1].release()
                        # self.yolo2main_status_msg.emit('Detection completed')
                        break
        except queue.Empty:
            print('yoloPredictor: queue.Empty')
            runFlag = False
            return
        except Exception as e:
            print(e)
            # self.yolo2main_status_msg.emit('%s' % e)

    def get_annotator(self, img):
        return Annotator(img, line_width=self.args.line_thickness, example=str(self.model.names))

    def preprocess(self, img):
        img = torch.from_numpy(img).to(self.model.device)
        img = img.half() if self.model.fp16 else img.float()  # uint8 to fp16/32
        img /= 255  # 0 - 255 to 0.0 - 1.0
        return img

    def postprocess(self, preds, img, orig_img):
        # important
        preds = ops.non_max_suppression(preds,
                                        self.conf_thres,
                                        self.iou_thres,
                                        agnostic=self.args.agnostic_nms,
                                        max_det=self.args.max_det,
                                        classes=self.args.classes)

        results = []
        for i, pred in enumerate(preds):
            orig_img = orig_img[i] if isinstance(orig_img, list) else orig_img
            shape = orig_img.shape
            pred[:, :4] = ops.scale_boxes(
                img.shape[2:], pred[:, :4], shape).round()
            path, _, _, _, _ = self.batch
            img_path = path[i] if isinstance(path, list) else path
            results.append(Results(orig_img=orig_img, path=img_path,
                           names=self.model.names, boxes=pred))
        return results

    # ç”»ç»“æœ
    def write_results(self, idx, results, batch):
        # idx æ˜¯ä¸€ä¸ªæ•´æ•°ï¼Œç”¨äºæŒ‡å®šæ‰¹å¤„ç†ä¸­çš„æŸä¸ªå›¾åƒï¼›
        # results æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­åŒ…å«åœ¨æ¨¡å‹ä¸­å¯¹ batch æ‰§è¡Œå‰å‘ä¼ é€’çš„ç»“æœï¼›
        # batch æ˜¯æ¨¡å‹è¾“å…¥çš„ä¸€ä¸ªæ‰¹å¤„ç†å¼ é‡ï¼Œå®ƒç”±ä¸‰ä¸ªå…ƒç´ ç»„æˆï¼špï¼Œim å’Œ im0ã€‚

        # å°†å…ƒç»„ batch ä¸­ä¸‰ä¸ªå˜é‡è§£åŒ…å­˜å‚¨åˆ° pã€im å’Œ im0 ä¸­ã€‚
        p, im, im0 = batch
        log_string = ''

        # ç”¨äºåˆ¤æ–­è¾“å…¥å›¾åƒçš„å½¢çŠ¶ï¼ˆshapeï¼‰æ˜¯å¦ä¸º 3Dï¼Œå¦‚æœæ˜¯åˆ™åœ¨å‰é¢æ·»åŠ ä¸€ä¸ªæ–°çš„ç»´åº¦ï¼Œä»¥è¡¨ç¤ºæ‰¹å¤„ç†ã€‚è¿™æ˜¯ä¸€ç§å¤„ç†ä¸åŒå¤§å°çš„è¾“å…¥å›¾åƒçš„å¸¸è§æ–¹æ³•ã€‚
        if len(im.shape) == 3:
            im = im[None]  # expand for batch dim
        self.seen += 1

        # ä½¿ç”¨ if/else è¯­å¥è®¾ç½®å˜é‡ imcï¼Œè¯¥å˜é‡å­˜å‚¨è¾“å…¥å›¾åƒçš„ä¸€ä¸ªå‰¯æœ¬ã€‚
        # å¦‚æœå‚æ•° save_cropï¼ˆåœ¨ self.args ä¸­ï¼‰ä¸ºçœŸï¼Œåˆ™å­˜å‚¨è£å‰ªçš„å›¾åƒï¼Œå¦åˆ™å­˜å‚¨åŸå§‹å›¾åƒã€‚
        imc = im0.copy() if self.args.save_crop else im0

        # æ£€æŸ¥è¾“å…¥æ•°æ®æ˜¯å¦æ¥è‡ªç½‘ç»œæ‘„åƒå¤´æˆ–å›¾åƒæ–‡ä»¶
        if self.source_type.webcam or self.source_type.from_img:  # batch_size >= 1         # attention
            log_string += f'{idx}: '
            frame = self.dataset.count
        else:
            frame = getattr(self.dataset, 'frame', 0)
        self.data_path = p
        self.txt_path = str(self.save_dir / 'labels' / p.stem) + \
            ('' if self.dataset.mode == 'image' else f'_{frame}')
        # log_string += '%gx%g ' % im.shape[2:]         # !!! don't add img size~
        self.annotator = self.get_annotator(im0)

        # ç»Ÿè®¡æ£€æµ‹åˆ°çš„ç›®æ ‡æ•°é‡å’Œç§ç±»çš„æ®µè½
        det = results[idx].boxes  # TODO: make boxes inherit from tensors

        if len(det) == 0:
            return f'{log_string}(no detections), '  # if no, send this~~

        # æ·»åŠ å½“å‰ç›®æ ‡æ•°é‡å’Œåç§°åˆ°æ—¥å¿—å­—ç¬¦ä¸²
        # ã€det.cls.unique() æ–¹æ³•è¿”å›äº† det.cls åˆ—ä¸­çš„æ‰€æœ‰å”¯ä¸€å€¼ã€‘
        for c in det.cls.unique():
            # det.cls == c è¿™ä¸ªæ¡ä»¶åˆ¤æ–­è¡¨è¾¾å¼ä¼šè¿”å›ä¸€ä¸ªç”±å¸ƒå°”å€¼ç»„æˆçš„æ•°ç»„
            n = (det.cls == c).sum()  # detections per class

            # it only recognizes license-plates and records the total number of license-plates
            if (self.model.names[int(c)] == 'license-plate'):
                # {'s' * (n > 1)}, "   # don't add 's'
                log_string = f"{n}~{self.model.names[int(c)]},"

        # now log_string is the classes ğŸ‘†
        # print(log_string)

        # write & save & draw
        for d in reversed(det):

            cls, conf = d.cls.squeeze(), d.conf.squeeze()

            # è·å–ç±»åˆ«  get category
            c = int(cls)  # integer class
            name = f'id:{int(d.id.item())} {self.model.names[c]}' if d.id is not None else self.model.names[c]

            # å¦‚æœä¸æ˜¯è½¦ç‰Œï¼Œåˆ™è·³è¿‡ï¼
            # if there is not a license-plate, jump it
            if (name != 'license-plate'):
                continue

            # ç”»è½¦ç‰Œ draw a license plate
            plate = de_lpr(d.xyxy.squeeze(), im0)
            plate = np.array(plate)
            car_number_laber = ""
            for i in range(0, plate.shape[1]):
                b = CHARS[plate[0][i]]
                car_number_laber += b

            def count_non_lowercase_chars(input_string):
                count = 0
                for char in input_string:
                    if not char.islower():
                        count += 1
                return count

            numStem = count_non_lowercase_chars(car_number_laber)
            if len(car_number_laber) < 7 or numStem < 6 or numStem > 7:
                continue

            replaceDic = {
                '8': 'B', '0': 'D', '1': 'I',
            }
            letter = car_number_laber[-numStem-1]
            if letter in replaceDic.keys():
                car_number_laber = car_number_laber[:-numStem-1] + \
                    replaceDic[letter] + car_number_laber[-numStem:]

            self.carNumList.append(car_number_laber[-numStem:])

            def find_most_common_string(strings: list):
                frequency_dict = {}
                for s in strings:
                    frequency_dict[s] = frequency_dict.get(s, 0) + 1
                mostCommonStr = max(frequency_dict, key=frequency_dict.get)
                return mostCommonStr

            if len(self.carNumList) == 8:
                mostNum = find_most_common_string(self.carNumList)
                self.carNumList.clear()
                print(mostNum, end=', ')
                print(count_non_lowercase_chars(mostNum) == 7)

            if self.save_txt:  # Write to file å†™å…¥æ–‡æœ¬æ–‡ä»¶

                line = (cls, *(d.xywhn.view(-1).tolist()), conf) \
                    if self.args.save_conf else (cls, *(d.xywhn.view(-1).tolist()))  # label format
                with open(f'{self.txt_path}.txt', 'a') as f:
                    f.write(('%g ' * len(line)).rstrip() % line + '\n')

            # æ£€æµ‹ç»“æœç»˜åˆ¶åˆ°å›¾åƒä¸Šï¼Œå¹¶æ˜¾ç¤ºå‡ºæ¥ã€‚
            # Add bbox to image(must)
            if self.save_res or self.args.save_crop or self.args.show or True:

                # å¦‚æœ self.args.hide_labels = Trueï¼Œåˆ™ä¸º None
                # å¦åˆ™ (name if self.args.hide_conf else f'{name} {conf:.2f}')
                # å¦‚æœ self.args.hide_conf = Trueï¼Œåˆ™ä¸º name
                # å¦åˆ™ f'{name} {conf:.2f}'
                self.annotator.box_label(
                    d.xyxy.squeeze(), car_number_laber, color=colors(c, True))

                # åŸæ ‡ç­¾ original label
                # label = None if self.args.hide_labels else (name if self.args.hide_conf else f'{name} {conf:.2f}')

            # å°†ç”»åœ¨å›¾åƒä¸Šçš„è¾¹ç•Œæ¡†åŒºåŸŸä¿å­˜ä¸ºä¸€ä¸ªå•ç‹¬çš„å›¾åƒæˆ–è€…è§†é¢‘æ–‡ä»¶
            if self.args.save_crop:
                save_one_box(d.xyxy,
                             imc,
                             file=self.save_dir / 'crops' /
                             self.model.model.names[c] /
                             f'{self.data_path.stem}.jpg',
                             BGR=True)

        return log_string
